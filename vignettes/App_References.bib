@article{Guo2020,
abstract = {Propensity score analysis is often used to address selection bias in program evaluation with observational data. However, a recent study suggested that propensity score matching may accomplish the opposite of its intended goal—in-creasing imbalance, inefficiency, model dependence, and bias. We assess common propensity score models and offer our responses to these criticisms. We used Monte Carlo methods to simulate two alternative settings of data creation—selection on observed variables versus selection on unobserved variables—andcomparedeightpro-pensity score models on bias reduction and sample-size retention. Based on the simulations, no single propensity score method reduced bias across all scenarios. Optimal results depend on the fit between assumptions embedded in the analytic model and the process of data generation. Methodologic knowledge of model assumptions and substantive knowledge of causal mechanisms, including sources of selection bias, should inform the choice of analytic strategies involving propensity scores.},
author = {Guo, Shenyang and Fraser, Mark and Chen, Qi},
doi = {10.1086/711393},
issn = {1948822X},
journal = {Journal of the Society for Social Work and Research},
keywords = {Endogeneity,Observational studies,Propensity score analysis,Propensity score matching,Selection bias},
month = {sep},
number = {3},
pages = {463--482},
publisher = {University of Chicago Press},
title = {{Propensity score analysis: Recent debate and discussion}},
volume = {11},
year = {2020}
}


@article{Hansen2008,
abstract = {The propensity score collapses the covariates of an observational study into a single measure summarizing their joint association with treatment conditions; prognostic scores summarize covariates' association with potential responses. As with propensity scores, stratification on prognostic scores brings to uncontrolled studies a concrete and desirable form of balance, a balance that is more familiar as an objective of experimental control. Like propensity scores, prognostic scores can reduce the dimension of the covariate, yet causal inferences conditional on them are as valid as are inferences conditional only on the unreduced covariate. As a method of adjustment unto itself, prognostic scoring has limitations not shared with propensity scoring, but it holds promise as a complement to the propensity score, particularly in certain designs for which unassisted propensity adjustment is difficult or infeasible. {\textcopyright} 2008 Biometrika Trust.},
author = {Hansen, Ben B.},
doi = {10.1093/biomet/asn004},
issn = {00063444},
journal = {Biometrika},
keywords = {Covariate balance,Matched sampling,Matching,Observational study,Quasi-experiment,Regression discontinuity,Subclassification},
number = {2},
pages = {481--488},
title = {{The prognostic analogue of the propensity score}},
volume = {95},
year = {2008}
}


@article{Jann2017,
abstract = {Ben Jann, 2017. "Why propensity scores should be used for matching," German Stata Users' Group Meetings 2017 01, Stata Users Group.},
author = {Jann, Ben},
title = {{Why Propensity Scores Should Be Used for Matching. 2017 German Stata Users Group Meeting. Berlin, June 23, 2017}},
url = {https://www.stata.com/meeting/germany17/slides/Germany17_Jann.pdf},
year = {2017}
}

@article{Koedinger2015,
abstract = {The printing press long ago and the computer today have made widespread access to information possible. Learning theorists have suggested, however, that mere information is a poor way to learn. Instead, more effective learning comes through doing. While the most popularized element of today's MOOCs are the video lectures, many MOOCs also include interactive activities that can afford learning by doing. This paper explores the learning benefits of the use of informational assets (e.g., videos and text) in MOOCs, versus the learning by doing opportunities that interactive activities provide. We find that students doing more activities learn more than students watching more videos or reading more pages. We estimate the learning benefit from extra doing (1 SD increase) to be more than six times that of extra watching or reading. Our data, from a psychology MOOC, is correlational in character, however we employ causal inference mechanisms to lend support for the claim that the associations we find are causal.},
author = {Koedinger, Kenneth R. and McLaughlin, Elizabeth A. and Kim, Jihee and Jia, Julianna Zhuxin and Bier, Norman L.},
doi = {10.1145/2724660.2724681},
isbn = {9781450334112},
journal = {L@S 2015 - 2nd ACM Conference on Learning at Scale},
keywords = {Course effectiveness,Learning by doing,Learning prediction,MOOCs,OER,Open education},
pages = {111--120},
title = {{Learning is not a spectator sport: Doing is better than watching for learning from a MOOC}},
year = {2015}
}

@article{King2019,
abstract = {We show that propensity score matching (PSM), an enormously popular method of preprocessing data for causal inference, often accomplishes the opposite of its intended goal—thus increasing imbalance, inefficiency, model dependence, and bias. The weakness of PSM comes from its attempts to approximate a completely randomized experiment, rather than, as with other matching methods, a more efficient fully blocked randomized experiment. PSM is thus uniquely blind to the often large portion of imbalance that can be eliminated by approximating full blocking with other matching methods. Moreover, in data balanced enough to approximate complete randomization, either to begin with or after pruning some observations, PSM approximates random matching which, we show, increases imbalance even relative to the original data. Although these results suggest researchers replace PSM with one of the other available matching methods, propensity scores have other productive uses.},
author = {King, Gary and Nielsen, Richard},
doi = {10.1017/pan.2019.11},
issn = {1047-1987},
journal = {Political Analysis},
keywords = {Mahalanobis distance matching,coarsened exact matching,matching,model dependence,propensity score matching},
month = {oct},
number = {4},
pages = {435--454},
title = {{Why Propensity Scores Should Not Be Used for Matching}},
url = {https://www.cambridge.org/core/product/identifier/S1047198719000111/type/journal_article},
volume = {27},
year = {2019}
}

@article{Li2013,
abstract = {Evidence-based management requires management scholars to draw causal inferences. Researchers generally rely on observational data sets and regression models where the independent variables have not been exogenously manipulated to estimate causal effects; however, using such models on observational data sets can produce a biased effect size of treatment intervention. This article introduces the propensity score method (PSM)—which has previously been widely employed in social science disciplines such as public health and economics—to the management field. This research reviews the PSM literature, develops a procedure for applying the PSM to estimate the causal effects of intervention, elaborates on the procedure using an empirical example, and discusses the potential application of the PSM in different management fields. The implementation of the PSM in the management field will increase researchers' ability to draw causal inferences using observational data sets.},
author = {Li, Mingxiang},
doi = {10.1177/1094428112447816},
issn = {1094-4281},
journal = {Organizational Research Methods},
keywords = {causal effect,matching,propensity score method},
month = {apr},
number = {2},
pages = {188--226},
title = {{Using the Propensity Score Method to Estimate Causal Effects}},
url = {http://journals.sagepub.com/doi/10.1177/1094428112447816},
volume = {16},
year = {2013}
}

@article{Lunceford2004,
abstract = {Estimation of treatment effects with causal interpretation from observational data is complicated because exposure to treatment may be confounded with subject characteristics. The propensity score, the probability of treatment exposure conditional on covariates, is the basis for two approaches to adjusting for confounding: methods based on stratification of observations by quantiles of estimated propensity scores and methods based on weighting observations by the inverse of estimated propensity scores. We review popular versions of these approaches and related methods offering improved precision, describe theoretical properties and highlight their implications for practice, and present extensive comparisons of performance that provide guidance for practical use. Copyright {\textcopyright} 2004 John Wiley & Sons, Ltd.},
author = {Lunceford, Jared K. and Davidian, Marie},
doi = {10.1002/sim.1903},
issn = {02776715},
journal = {Statistics in Medicine},
keywords = {Covariate balance,Double robustness,Inverse-probability-of-treatment-weighted-estimato,Observational data},
month = {oct},
number = {19},
pages = {2937--2960},
pmid = {15351954},
title = {{Stratification and weighting via the propensity score in estimation of causal treatment effects: a comparative study}},
url = {https://onlinelibrary.wiley.com/doi/10.1002/sim.1903},
volume = {23},
year = {2004}
}

@article{Morris2019,
abstract = {Simulation studies are computer experiments that involve creating data by pseudo-random sampling. A key strength of simulation studies is the ability to understand the behavior of statistical methods because some “truth” (usually some parameter/s of interest) is known from the process of generating the data. This allows us to consider properties of methods, such as bias. While widely used, simulation studies are often poorly designed, analyzed, and reported. This tutorial outlines the rationale for using simulation studies and offers guidance for design, execution, analysis, reporting, and presentation. In particular, this tutorial provides a structured approach for planning and reporting simulation studies, which involves defining aims, data-generating mechanisms, estimands, methods, and performance measures (“ADEMP”); coherent terminology for simulation studies; guidance on coding simulation studies; a critical discussion of key performance measures and their estimation; guidance on structuring tabular and graphical presentation of results; and new graphical presentations. With a view to describing recent practice, we review 100 articles taken from Volume 34 of Statistics in Medicine, which included at least one simulation study and identify areas for improvement.},
archivePrefix = {arXiv},
arxivId = {1712.03198},
author = {Morris, Tim P. and White, Ian R. and Crowther, Michael J.},
doi = {10.1002/SIM.8086},
eprint = {1712.03198},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {Monte Carlo,graphics for simulation,simulation design,simulation reporting,simulation studies},
month = {may},
number = {11},
pages = {2074--2102},
pmid = {30652356},
publisher = {John Wiley and Sons Ltd},
title = {{Using simulation studies to evaluate statistical methods}},
volume = {38},
year = {2019}
}


@phdthesis{Ripollone2019,
abstract = {Certain pitfalls associated with propensity score matching have come to light, recently. The extent to which these pitfalls might threaten validity and precision in pharmacoepidemiologic research, for which propensity score matching often is used, is uncertain. We evaluated the “propensity score matching paradox” – the tendency for covariate imbalance to increase in a propensity score-matched dataset upon continuous pruning of matched sets – as well as the utility of coarsened exact matching, a technique that has been posed as a preferable alternative to propensity score matching, especially in light of the “propensity score matching paradox”. We show that the “propensity score matching paradox” may not threaten causal inference that is based on propensity score matching in typical pharmacoepidemiologic settings to the extent predicted by previous research. Moreover, even though coarsened exact matching substantially improves covariate balance, it may not be optimal in typical pharmacoepidemiologic settings due to the extreme loss of study size (and resulting increase in bias and variance) that may be required to build the matched dataset. Finally, we explain variability in 1:1 propensity score matching without replacement as well as methods that were developed to account for this variability, with application of these methods to an example claims-based study.},
author = {Ripollone, John Edward},
keywords = {Epidemiology},
school = {Boston University},
title = {{Exploration of structural and statistical biases in the application of propensity score matching to pharmacoepidemiologic data}},
type = {Thesis/Dissertation},
url = {https://hdl.handle.net/2144/36025},
year = {2019}
}

@article{Ripollone2018,
abstract = {Recent work has demonstrated that propensity score matching may lead to increased covariate imbalance, even with the corresponding decrease in propensity score distance between matched units. The extent to which this paradoxical phenomenon might harm causal inference in real epidemiologic studies has not been explored. We evaluated the effect of this phenomenon using insurance claims data from the Pharmaceutical Assistance Contract for the Elderly (1999-2002) and Medicaid Analytic eXtract (2000-2007) databases in the United States. For each data set, we created several 1:1 propensity-score-matched data sets by manipulating the size of the covariate set used to generate propensity scores, the index exposure prevalence in the prematched data set, and the matching algorithm. We matched all index units, then progressively pruned matched sets in order of decreasing propensity score distance, calculating covariate imbalance after each pruning. Although covariate imbalance sometimes increased after progressive pruning of matched sets, the application of commonly used propensity score calipers for defining an acceptable match stopped pruning near the lowest region of the imbalance trend and resulted in an improvement over the imbalance in the prematched data set. Thus, propensity score matching does not appear to induce increased covariate imbalance when standard propensity score calipers are applied in these types of pharmacoepidemiologic studies.},
author = {Ripollone, John E. and Huybrechts, Krista F. and Rothman, Kenneth J. and Ferguson, Ryan E. and Franklin, Jessica M.},
doi = {10.1093/aje/kwy078},
issn = {14766256},
journal = {American Journal of Epidemiology},
keywords = {Covariate balance,Mahalanobis distance matching,Propensity score,Propensity score matching},
number = {9},
pages = {1951--1961},
pmid = {29750409},
title = {{Implications of the propensity score matching paradox in pharmacoepidemiology}},
volume = {187},
year = {2018}
}

@article{Rosenbaum1983,
abstract = {The propensity score is the conditional probability of assignment to a particular treatment given a vector of observed covariates. Both large and small sample theory show that adjustment for the scalar propensity score is sufficient to remove bias due to all observed covariates. Applications include: (i) matched sampling on the univariate propensity score, which is a generalization of discriminant matching, (ii) multivariate adjustment by subclassification on the propensity score where the same subclasses are used to estimate treatment effects for all outcome variables and in all subpopulations, and (iii) visual representation of multivariate covariance adjustment by a two- dimensional plot. {\textcopyright} 1983 Biometrika Trust.},
author = {Rosenbaum, PAUL R. and Rubin, DONALD B.},
doi = {10.1093/biomet/70.1.41},
issn = {0006-3444},
journal = {Biometrika},
keywords = {Covariance adjustment,Direct adjustment,Discriminant matching,Matched sampling,Nonrandomized study,Standardization,Stratification,Subclassification},
month = {apr},
number = {1},
pages = {41--55},
title = {{The central role of the propensity score in observational studies for causal effects}},
url = {https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/70.1.41},
volume = {70},
year = {1983}
}


@incollection{Rosenbaum2006,
abstract = {The propensity score is the conditional probability of assignment to a particular treatment given a vector of observed covariates. Both large and small sample theory show that adjustment for the scalar propensity score is sufficient to remove bias due to all observed covariates. Applications include: (i) matched sampling on the univariate propensity score, which is a generalization of discriminant matching, (ii) multivariate adjustment by subclassification on the propensity score where the same subclasses are used to estimate treatment effects for all outcome variables and in all subpopulations, and (iii) visual representation of multivariate covariance adjustment by a two-dimensional plot.},
address = {Cambridge},
author = {Rosenbaum, PAUL R. and Rubin, DONALD B.},
booktitle = {Matched Sampling for Causal Effects},
doi = {10.1017/CBO9780511810725.016},
isbn = {9780511810725},
issn = {0006-3444},
keywords = {Covariance adjustment,Direct adjustment,Discriminant matching,Matched sampling,Nonrandomized study,Standardization,Stratification,Subclassification},
month = {apr},
number = {1083},
pages = {170--184},
publisher = {Cambridge University Press},
title = {{The Central Role of the Propensity Score in Observational Studies for Causal Effects}},
url = {https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/70.1.41 https://www.cambridge.org/core/product/identifier/CBO9780511810725A021/type/book_part},
volume = {70},
year = {2006}
}

@article{Wang2021,
abstract = {Propensity score matching (PSM) has been widely used to reduce confounding biases in observational studies. Its properties for statistical inference have also been investigated and well documented. However, some recent publications showed concern of using PSM, especially on increasing postmatching covariate imbalance, leading to discussion on whether PSM should be used or not. We review empirical and theoretical evidence for and against its use in practice and revisit the property of equal percent bias reduction and adapt it to more practical situations, showing that PSM has some additional desirable properties. With a small simulation, we explore the impact of caliper width on biases due to mismatching in matched samples and due to the difference between matched and target populations and show some issue of PSM may be due to inadequate caliper selection. In summary, we argue that the right question should be when and how to use PSM rather than to use or not to use it and give suggestions accordingly.},
author = {Wang, Jixian},
doi = {10.1002/pst.2051},
issn = {1539-1604},
journal = {Pharmaceutical Statistics},
month = {jan},
number = {1},
pages = {15--24},
title = {{To use or not to use propensity score matching?}},
url = {https://onlinelibrary.wiley.com/doi/10.1002/pst.2051},
volume = {20},
year = {2021}
}

@misc{RStudioTeam2020,
address = {Boston, MA},
author = {{RStudio Team}},
publisher = {RStudio, PBC},
title = {{RStudio: Integrated Development for R.}},
url = {http://www.rstudio.com/},
year = {2020}
}

@book{Fay2021,
author = {Fay, Colin and Rochette, S{\'{e}}bastien and Guyader, Vincent and Girard, Cervan},
edition = {1st},
isbn = {9780367466022},
pages = {398},
publisher = {Chapman and Hall/CRC},
title = {{Engineering Production-Grade Shiny Apps}},
url = {https://engineering-shiny.org/},
year = {2021}
}

@misc{icons,
	title = {Match icons created by Freepik - Flaticon},
	url = {https://www.flaticon.com/free-icons/match},
	urldate = {2022-10-24}
}

@article{CEinObsData,
title = {Causal inference and effect estimation using observational data},
copyright = {Author(s) (or their employer(s)) 2022. Re-use permitted under CC BY. Published by BMJ.},
language = {eng},
address = {LONDON},
author = {Igelström, Erik and Craig, Peter and Lewsey, Jim and Lynch, John and Pearce, Anna and Katikireddi, Srinivasa Vittal},
keywords = {Causality ; Epidemiology ; Expected values ; Glossary ; Life Sciences & Biomedicine ; Medical research ; methods ; Public Environmental & Occupational Health ; research design ; Research methodology ; Science & Technology ; Statistical inference ; statistics ; study design ; Variables},
issn = {0143-005X},
abstract = {Observational studies aiming to estimate causal effects often rely on conceptual frameworks that are unfamiliar to many researchers and practitioners. We provide a clear, structured overview of key concepts and terms, intended as a starting point for readers unfamiliar with the causal inference literature. First, we introduce theoretical frameworks underlying causal effect estimation methods: the counterfactual theory of causation, the potential outcomes framework, structural equations and directed acyclic graphs. Second, we define the most common causal effect estimands, and the issues of effect measure modification, interaction and mediation (direct and indirect effects). Third, we define the assumptions required to estimate causal effects: exchangeability, positivity, consistency and non-interference. Fourth, we define and explain biases that arise when attempting to estimate causal effects, including confounding, collider bias, selection bias and measurement bias. Finally, we describe common methods and study designs for causal effect estimation, including covariate adjustment, G-methods and natural experiment methods.},
journal = {Journal of epidemiology and community health (1979)},
pages = {960--966},
volume = {76},
publisher = {BMJ Publishing Group Ltd},
number = {11},
year = {2022},
}

@article{LeeBrianK.2010Ipsw,
issn = {0277-6715},
abstract = {Machine learning techniques such as classification and regression trees (CART) have been suggested as promising alternatives to logistic regression for the estimation of propensity scores. The authors examined the performance of various CART‐based propensity score models using simulated data. Hypothetical studies of varying sample sizes (n=500, 1000, 2000) with a binary exposure, continuous outcome, and 10 covariates were simulated under seven scenarios differing by degree of non‐linear and non‐additive associations between covariates and the exposure. Propensity score weights were estimated using logistic regression (all main effects), CART, pruned CART, and the ensemble methods of bagged CART, random forests, and boosted CART. Performance metrics included covariate balance, standard error, per cent absolute bias, and 95 per cent confidence interval (CI) coverage. All methods displayed generally acceptable performance under conditions of either non‐linearity or non‐additivity alone. However, under conditions of both moderate non‐additivity and moderate non‐linearity, logistic regression had subpar performance, whereas ensemble methods provided substantially better bias reduction and more consistent 95 per cent CI coverage. The results suggest that ensemble methods, especially boosted CART, may be useful for propensity score weighting. Copyright © 2009 John Wiley & Sons, Ltd.},
journal = {Statistics in medicine},
pages = {337--346},
volume = {29},
publisher = {John Wiley & Sons, Ltd},
number = {3},
year = {2010},
title = {Improving propensity score weighting using machine learning},
copyright = {Copyright © 2009 John Wiley & Sons, Ltd.},
language = {eng},
address = {Chichester, UK},
author = {Lee, Brian K. and Lessler, Justin and Stuart, Elizabeth A.},
keywords = {Artificial Intelligence ; Bias ; Boosting ; CART ; Computer Simulation ; Data mining ; Ensemble methods ; Estimating techniques ; Life Sciences & Biomedicine ; Logistic Models ; Machine learning ; Mathematical & Computational Biology ; Mathematics ; Medical Informatics ; Medicine Research & Experimental ; Nonlinear Dynamics ; Performance evaluation ; Physical Sciences ; Propensity Score ; Public Environmental & Occupational Health ; Regression Analysis ; Research & Experimental Medicine ; Science & Technology ; Simulation ; Statistics & Probability ; Weighting},
}

@article{Mahalanobis1936,
address = {Calcutta},
author = {Mahalanobis, Prasanta C.},
journal = {On the generalized distance in statistics},
number = {1},
pages = {49--55},
publisher = {National Institute of Sciences of India},
title = {{On the generalized distance in statistics.}},
url = {http://library.isical.ac.in:8080/jspui/bitstream/10263/6765/1/Vol02_1936_1_Art05-pcm.pdf},
volume = {2},
year = {1936}
}

@article{Mahalanobis1927,
author = {Mahalanobis, Prasanta C.},
journal = {Journal and Proceedings of the Asiatic Society of Bengal},
pages = {301--333},
title = {{Analysis of race mixture in Bengal}},
volume = {23},
year = {1927}
}


@article{MatchIt,
	title = {{\textbraceleft}MatchIt{\textbraceright}: Nonparametric Preprocessing for Parametric Causal Inference},
	author = {Ho, Daniel E. and Imai, Kosuke and King, Gary and Stuart, Elizabeth A.},
	year = {2011},
	date = {2011},
	volume = {42},
	doi = {10.18637/jss.v042.i08}
}

@Manual{Shiny,
  title = {shiny: Web Application Framework for R},
  author = {Winston Chang and Joe Cheng and JJ Allaire and Carson Sievert and Barret Schloerke and Yihui Xie and Jeff Allen and Jonathan McPherson and Alan Dipert and Barbara Borges},
  year = {2022},
  note = {R package version 1.7.3.9001},
  url = {https://shiny.rstudio.com/},
}

@article{pkgdown,
	title = {pkgdown: Make Static HTML Documentation for a Package},
	author = {Wickham, Hadley and Hesselberth, Jay and Salmon, {Maëlle}},
	year = {2022},
	date = {2022},
	url = {https://CRAN.R-project.org/package=pkgdown}
}

@article{ggplot2,
	title = {ggplot2: Elegant Graphics for Data Analysis},
	author = {Wickham, Hadley},
	year = {2016},
	date = {2016},
	url = {https://ggplot2.tidyverse.org}
}

@article{plotly,
	title = {Interactive Web-Based Data Visualization with R, plotly, and shiny},
	author = {Sievert, Carson},
	year = {2020},
	date = {2020},
	url = {https://plotly-r.com}
}

@article{dplyr,
	title = {dplyr: A Grammar of Data Manipulation},
	author = {Wickham, Hadley and {François}, Romain and Henry, Lionel and {Müller}, Kirill},
	year = {2022},
	date = {2022},
	url = {https://CRAN.R-project.org/package=dplyr}
}

@article{MASS,
	title = {Modern Applied Statistics with S},
	author = {Venables, W. N. and Ripley, B. D.},
	year = {2002},
	date = {2002},
	url = {https://www.stats.ox.ac.uk/pub/MASS4/}
}

@article{boot,
	title = {boot: Bootstrap R (S-Plus) Functions},
	author = {Canty, Angelo and Ripley, B. D.},
	year = {2021},
	date = {2021}
}

@article{smd,
	title = {smd: Compute Standardized Mean Differences},
	author = {Saul, Bradley},
	year = {2020},
	date = {2020},
	url = {https://CRAN.R-project.org/package=smd}
}

@article{stats,
	title = {R: A Language and Environment for Statistical Computing},
	author = {, R Core Team},
	year = {2022},
	date = {2022},
	url = {https://www.R-project.org/}
}

@article{optmatch,
	title = {Optimal full matching and related designs via network flows},
	author = {Hansen, Ben B. and Klopfer, Stephanie Olsen},
	year = {2006},
	date = {2006},
	volume = {15}
}

@Article{mplot,
  title = {{mplot}: An {R} Package for Graphical Model Stability and
    Variable Selection Procedures},
  author = {Garth Tarr and Samuel M{\"u}ller and Alan H. Welsh},
  journal = {Journal of Statistical Software},
  year = {2018},
  volume = {83},
  number = {9},
  pages = {1--28},
  doi = {10.18637/jss.v083.i09},
}
